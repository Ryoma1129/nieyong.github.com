<!DOCTYPE html>
<html>
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
	<title>OS-内存管理</title>

  	<link rel="stylesheet" href="templates/SyntaxHighlighter.css"></link>
	<link rel="stylesheet" href="templates/style.css">
	
	<script	src="https://ajax.googleapis.com/ajax/libs/jquery/1.8.2/jquery.min.js"></script>
	<script language="javascript" src="templates/shCore.js"></script>
	<script language="javascript" src="templates/shBrushCpp.js"></script>
	<script language="javascript" src="templates/shBrushJScript.js"></script>
	<script language="javascript" src="templates/shBrushPhp.js"></script>
	<script language="javascript" src="templates/shBrushJava.js"></script>
	<script language="javascript" src="templates/shBrushXml.js"></script>
	<script language="javascript" src="templates/shBrushCss.js"></script>
	<script language="javascript" src="templates/shBrushObjectiveC.js"></script>
	
	<script language="javascript" src="templates/vimwiki.js"></script>
</head>


<body>
    <div class="navbar">
      <div class="navbar-container">
	  <a class="brand" href="index.html">NieNet</a>
	  <div class="nav-collapse">
		<ul class="nav">
		  <li><a href="index.html">主页</a></li>
		  <li><a href="about.html">关于</a></li>
		</ul>
	  </div><!--/.nav-collapse -->
      </div>
    </div>

    <div class="container">
	<div id="content">
	
<h2 id="toc_0.1">虚拟存储系统的存储器组织</h2>
<p>
参考《ARM嵌入式系统开发-软件设计与优化》14.2.3 虚存系统的存储器组织。
</p>

<p>
典型的，页表存放在主存的一块空间中，这片空间虚拟地址到物理地址的映射是固定的。如图所示，存储器中的这块固定空间还包含操作系统内核以及一些其它的进程。
</p>

<p>
<a href="CPU体系架构-image/os_mm/mmu_mm_model.png.html">CPU体系架构-image/os_mm/mmu_mm_model.png</a>
</p>

<p>
这种固定映射的好处在任务切换中可以看到。把系统软件放在一个固定的虚拟存储器位置，这样消除了一些存储器管理任务和流水线影响。
</p>

<p>
在虚存的一块固定空间（对所有的用户任务都可见）上共享系统软件，一个系统调用可以直接跳转到这块系统空间，而不必担心需要将页表改为映射到内核进程中。将内核代码和数据映射到所有任务的同一个虚拟地址，避免了需要改变存储器映射，并且避免了需要有消耗一个时间片的独立内核进程。
</p>

<p>
对上面这段话的理解还不深刻。2012.11.9
</p>

<p>
下面就具体来看看Linux系统的虚拟存储系统的布局。
</p>

<h2 id="toc_0.2">Linux虚拟存储空间的组织</h2>
<ul>
<li>
内核直接映射空间，Linux 规定“内核直接映射空间” 最多映射 896M 物理内存。

<li>
内核动态映射空间

<li>
高端内存是指物理地址大于 896M 的内存。

</ul>

<p>
Linux 2.6内核使用了许多技术来改进对虚拟内存空间的使用，以及对内存映射的优化，使得Linux比以往任何时候都更适用于企业。包括反向映射（reverse mapping）、使用更大的内存页、页表条目存储在高端内存中，以及更稳定的管理器。
</p>

<p>
虚拟地址如何转为物理地址,这个转换过程由操作系统和CPU共同完成。操作系统为CPU设置好页表。CPU通过MMU单元进行地址转换。CPU做出映射的前提是操作系统要为其准备好内核页表，而对于页表的设置，内核在系统启动的初期和系统初始化完成后都分别进行了设置。
</p>

<p>
虽然内核空间占据了每个虚拟空间中的最高1GB字节，但映射到物理内存却总是从最低地址（0x00000000）开始。对内核空间来说，其地址映射是很简单的线性映射，0xC0000000就是物理地址与线性地址之间的位移量，在Linux代码中就叫做PAGE_OFFSET。
</p>

<p>
<a href="CPU体系架构-image/os_mm/linux_virtual_mem.png.html">CPU体系架构-image/os_mm/linux_virtual_mem.png</a>
</p>

<p>
下面对上图说明：
</p>

<ul>
<li>
Linux虚拟地址空间：又叫做线性地址空间，是指Linux系统中从0x00000000到0xFFFFFFFF整个4GB虚拟存储空间。

<li>
内核空间：内核空间表示运行在处理器最高级别的超级用户模式（supervisor mode）下的代码或数据，也就是内核代码。内核空间占用从0xC0000000到0xFFFFFFFF的1GB线性地址空间，内核线性地址空间由所有用户进程共享，但只有运行在内核态时才能访问，用户进程可以通过系统调用切换到内核态访问内核空间，进程运行在内核态时所产生的地址都属于内核空间。

<li>
用户空间：又叫做进程空间，用户空间占用从0x00000000到0xBFFFFFFF共3GB的线性地址空间，每个进程都有一个独立的3GB用户空间，所以用户空间由每个进程独有，但是内核线程没有用户空间，因为它不产生用户空间地址。另外子进程共享（继承）父进程的用户空间只是使用与父进程相同的用户线性地址到物理内存地址的映射关系，而不是共享父进程用户空间。运行在用户态和内核态的进程都可以访问用户空间。

<li>
内核逻辑地址空间：又叫做 <strong>内核直接映射区、物理内存映射区</strong> ，是指从PAGE_OFFSET(3G)到high_memory(实际系统拥有的物理内存的大小，最大896MB)之间的线性地址空间，是系统物理内存映射区，它映射了全部或部分（如果系统包含高端内存）物理内存。内核逻辑地址空间与图18-4中的系统RAM内存物理地址空间是一一对应的（包括内存孔洞也是一一对应的），内核逻辑地址空间中的地址与RAM内存物理地址空间中对应的地址只差一个固定偏移量（3G），如果RAM内存物理地址空间从0x00000000地址编址，那么这个偏移量就是PAGE_OFFSET。

<li>
Linux高端虚拟地址空间：把high_memory以上的虚拟地址空间称为高端虚拟地址空间，如果high_memory为896MB，那么就还剩余128MB的高端虚拟地址空间。该部分地址虚拟地址空间是留给<code>vmalloc()</code>函数使用，所以这一段空间又被称为 <strong>动态映射区</strong> 。在没有足够的连续物理页面的情况下，vmalloc仍然可以利用页表的映射关系分配虚拟地址连续的内存。其中，图上4KB的灰色间隙时用来检测错误，为一个page大小。有关<code>vmalloc()</code>函数的知识，后面会有详细的讲解。

<li>
高端内存：低端内存地址之上的物理内存是高端内存（物理内存896MB之上，并不是所有系统都有高端内存，物理内存必须大于896MB），高端内存在Linux线性地址空间中没有固定的一一对应的内核逻辑地址，系统初始化过程中不会为这些内存建立映射页表将其固定映射到Linux线性地址空间，而是需要使用高端内存的时候才为分配的高端物理内存建立映射页表，使其能够被内核使用，否则不能被使用。高端内存的物理地址与线性地址之间的转换不能使用上面的<code>__pa(x)</code>和<code>__va(x)</code>宏。

</ul>


<h2 id="toc_0.3">linux页表映射机制的建立</h2>
<p>
linux页表映射机制的建立分为两个阶段，第一个阶段是内核进入保护模式之前要先建立一个临时内核页表并开启分页功能，因为在进入保护模式后，内核继续初始化直到建立完整的内存映射机制之前，仍然需要用到页表来映射相应的内存地址。对x86 32位内核，这个工作在保护模式下的内核入口函数<code>arch/x86/kernel/head_32.S:startup_32()</code>中完成。
</p>

<p>
第二阶段是建立完整的内存映射机制，在在<code>setup_arch()---&gt;arch/x86/mm/init.c:init_memory_mapping()</code>中完成。注意对于物理地址扩展（PAE)分页机制，Intel通过在处理器上把管脚数从32增加到36已经满足了这些需求，寻址能力可以达到64GB。不过，只有引入一种新的分页机制把32位线性地址转换为36位物理地址才能使用所增加的物理地址。linux为对多种体系的支持，选择了一套简单的通用实现机制。在这里只分析x86 32位下的实现。
</p>

<p>
<a href="Linux内存管理模块代码分析.html">Linux内存管理模块代码分析</a>
</p>

<h2 id="toc_0.4">Linux中的分段策略</h2>
<p>
段机制在Linux里用得有限，并没有被完全利用。
</p>

<p>
每个任务并未分别安排各自独立的数据段、代码段，而是仅仅最低限度的利用段机制来隔离用户数据和系统数据――Linux只安排了四个范围一样的段，内核数据段，内核代码段，用户数据段，用户代码段，它们都覆盖0-4G的空间，所不同的是各段属性不同，内核段特权级为0，用户段特权级为3。这样分段，避免了逻辑地址到线性地址转换步骤(逻辑地址就等于线性地址)，但仍然保留了段的等级这层最基本保护。
</p>

<p>
每个用户进程都可以看到4G大小的线性空间，其中0-3G是用户空间，用户态进程可以直接访问；从3G-4G空间为内核空间，存放内核代码和数据，只有内核态进程能够直接访问，用户态进程不能直接访问，只能通过系统调用和中断进入内核空间，而这是就要进行特权切换。 
</p>

<h3 id="toc_0.4.1">特权切换</h3>
<p>
说到特权切换，就离不开任务门，陷阱门/中断门等概念。陷阱门和中断门是在发生陷阱和中断时，进入内核空间的通道。调用门是用户空间程序相互访问时所需要的通道，任务门比较特殊，它不含如何寻址，而是服务于任务切换（但linux任务切换时并未真正采用它，它太麻烦了）。
</p>

<h2 id="toc_0.5">Linux中的分页策略</h2>
<p>
Linux中每个进程都会有个自的的页表，保证每个进程虚拟地址不会映射到相同的物理地址上。这样进程之间相互独立，各自的数据隔离，防止了信息泄漏。
</p>

<p>
<a href="CPU体系架构-image/os_mm/mm_virt_arch.png.html">CPU体系架构-image/os_mm/mm_virt_arch.png</a>
</p>

<p>
另外需要注意的是，内核作为必须保护的单独部分，它有自己独立的页表来映射内核空间(并非全部空间，仅仅是物理内存大小的空间)，该页表<code>swapper_pg_dir</code>被静态分配，它只来映射内核空间（<code>swapper_pg_dir</code>只用到768项以后的项――768个页目录可映射3G空间）。这个独立页表保证了内核虚拟空间独立于其他用户程序空间，也就是说其他进程通常状态和内核是没有联系的(在编译内核的时候，内核代码被制定链接到3G以上空间)，因而内核数据也就自然被保护起来了。
</p>

<h3 id="toc_0.5.1">用户进程需要访问内核空间</h3>
<p>
Linux采用了个巧妙的方法：用户进程页表的前768项映射进程空间（&lt;3G，因为LDT 中只指定基地址为0,范围只能到0xc0000000），如果进程要访问内核空间，如调用系统调用，则进程的页目录中768项后的表项将指向<code>swapper_pg_dir</code>的768项后的项，所以一旦用户陷入内核,就开始使用内核的页表<code>swapper_pg_dir</code>了，也就是说可以访问内核空间了。
</p>

<h2 id="toc_0.6">物理内存管理（页管理）</h2>
<ul>
<li>
Linux内核中空闲页面的组织和管理使用伙伴算法；

</ul>

<p>
Linux内核管理物理内存是通过分页机制实现的，它将整个内存划分成无数个4k（在i386体系结构中）大小的页，从而分配和回收内存的基本单位便是内存页了。利用分页管理有助于灵活分配内存地址，因为分配时不必要求必须有大块的连续内存（还有些情况必须要求内存连续，比如DMA传输中使用的内存，由于不涉及页机制所以必须连续分配。），系统可以东一页、西一页的凑出所需要的内存供进程使用。虽然如此，但是实际上系统使用内存时还是倾向于分配连续的内存块， <strong>因为分配连续内存时，页表不需要更改，因此能降低TLB的刷新率</strong> （频繁刷新会在很大程度上降低访问速度）。
</p>

<p>
鉴于上述需求，内核分配物理页面时为了尽量减少不连续情况，采用了“伙伴”关系来管理空闲页面。伙伴关系分配算法大家应该不陌生――几乎所有操作系统方面的书都会提到，我们不去详细说它了，如果不明白可以参看有关资料。这里只需要大家明白Linux中空闲页面的组织和管理利用了伙伴关系，因此空闲页面分配时也需要遵循伙伴关系，最小单位只能是2的幂倍页面大小。内核中分配空闲页面的基本函数是<code>get_free_page/get_free_pages</code>，它们或是分配单页或是分配指定的页面（2、4、8…512页）。
</p>
<blockquote>
注意：get_free_page是在内核中分配内存，不同于malloc在用户空间中分配，malloc利用堆动态分配，实际上是调用brk()系统调用，该调用的作用是扩大或缩小进程堆空间（它会修改进程的brk域）。如果现有的内存区域不够容纳堆空间，则会以页面大小的倍数为单位，扩张或收缩对应的内存区域，但brk值并非以页面大小为倍数修改，而是按实际请求修改。 <strong>因此Malloc在用户空间分配内存可以以字节为单位分配,但内核在内部仍然会是以页为单位分配的。</strong>
</blockquote>

<p>
另外,需要提及的是，物理页在系统中由页结构体<code>struct page</code>描述，系统中所有的页面都存储在数组<code>mem_map[]</code>中，可以通过该数组找到系统中的每一页（空闲或非空闲）。而其中的空闲页面则可由上述提到的以伙伴关系组织的空闲页链表<code>free_area[MAX_ORDER]</code>来索引。
</p>

<h2 id="toc_0.7">内核内存使用</h2>
<p>
对内核虚拟地址空间（3G-4G）的使用和管理，区别于进程虚拟地址空间（0-3G）。
</p>

<h3 id="toc_0.7.1">Slab</h3>
<p>
所谓尺有所长，寸有所短。以页为最小单位分配内存对于内核管理系统中的物理内存来说的确比较方便，但内核自身最常使用的内存却往往是很小（远远小于一页）的内存块――比如存放文件描述符、进程描述符、虚拟内存区域描述符等行为所需的内存都不足一页。这些用来存放描述符的内存相比页面而言，就好比是面包屑与面包。一个整页中可以聚集多个这些小块内存；而且这些小块内存块也和面包屑一样频繁地生成/销毁。
</p>

<p>
为了满足内核对这种小内存块的需要，Linux系统采用了一种被称为slab分配器的技术。Slab分配器的实现相当复杂，但原理不难，其核心思想就是“存储池”的运用。内存片段（小块内存）被看作对象，当被使用完后，并不直接释放而是被缓存到“存储池”里，留做下次使用，这无疑避免了频繁创建与销毁对象所带来的额外负载。
</p>

<p>
Slab技术不但避免了内存内部分片（下文将解释）带来的不便（引入Slab分配器的主要目的是为了减少对伙伴系统分配算法的调用次数――频繁分配和回收必然会导致内存碎片――难以找到大块连续的可用内存），而且可以很好地利用硬件缓存提高访问速度。
</p>

<p>
Slab并非是脱离伙伴关系而独立存在的一种内存分配方式，slab仍然是建立在页面基础之上，换句话说，Slab将页面（来自于伙伴关系管理的空闲页面链表）撕碎成众多小内存块以供分配，slab中的对象分配和销毁使用<code>kmem_cache_alloc</code>与<code>kmem_cache_free</code>。
</p>

<h3 id="toc_0.7.2">Kmalloc</h3>
<p>
Slab分配器不仅仅只用来存放内核专用的结构体，它还被用来处理内核对小块内存的请求。当然鉴于Slab分配器的特点，一般来说内核程序中对小于一页的小块内存的请求才通过Slab分配器提供的接口<code>Kmalloc</code>来完成（虽然它可分配32 到131072字节的内存）。从内核内存分配的角度来讲，<code>kmalloc</code>可被看成是<code>get_free_page(s)</code>的一个有效补充，内存分配粒度更灵活了。
</p>

<p>
有兴趣的话，可以到<code>/proc/slabinfo</code>中找到内核执行现场使用的各种slab信息统计，其中你会看到系统中所有slab的使用信息。从信息中可以看到系统中除了专用结构体使用的slab外，还存在大量为Kmalloc而准备的Slab（其中有些为dma准备的）。
</p>
 
<h3 id="toc_0.7.3">内核非连续内存分配（Vmalloc）</h3>
<p>
伙伴关系也好、slab技术也好，从内存管理理论角度而言目的基本是一致的，它们都是为了防止“分片”，不过分片又分为外部分片和内部分片之说，所谓内部分片是说系统为了满足一小段内存区（连续）的需要，不得不分配了一大区域连续内存给它，从而造成了空间浪费；外部分片是指系统虽有足够的内存，但却是分散的碎片，无法满足对大块“连续内存”的需求。无论何种分片都是系统有效利用内存的障碍。slab分配器使得一个页面内包含的众多小块内存可独立被分配使用，避免了内部分片，节约了空闲内存。伙伴关系把内存块按大小分组管理，一定程度上减轻了外部分片的危害，因为页框分配不在盲目，而是按照大小依次有序进行，不过伙伴关系只是减轻了外部分片，但并未彻底消除。你自己比划一下多次分配页面后，空闲内存的剩余情况吧。
</p>

<p>
所以避免外部分片的最终思路还是落到了如何利用不连续的内存块组合成“看起来很大的内存块”――这里的情况很类似于用户空间分配虚拟内存，内存逻辑上连续，其实映射到并不一定连续的物理内存上。Linux内核借用了这个技术，允许内核程序在内核地址空间中分配虚拟地址，同样也利用页表（内核页表）将虚拟地址映射到分散的内存页上。以此完美地解决了内核内存使用中的外部分片问题。内核提供<code>vmalloc</code>函数分配内核虚拟内存，该函数不同于<code>kmalloc</code>，它可以分配较<code>Kmalloc</code>大得多的内存空间（可远大于128K，但必须是页大小的倍数），但相比<code>Kmalloc</code>来说,<code>Vmalloc</code>需要对内核虚拟地址进行重映射，必须更新内核页表，因此分配效率上要低一些（用空间换时间）
</p>

<p>
与用户进程相似,内核也有一个名为<code>init_mm</code>的<code>mm_strcut</code>结构来描述内核地址空间，其中页表项<code>pdg=swapper_pg_dir</code>包含了系统内核空间（3G-4G）的映射关系。因此<code>vmalloc</code>分配内核虚拟地址必须更新内核页表，而<code>kmalloc</code>或<code>get_free_page</code>由于分配的连续内存，所以不需要更新内核页表。
</p>

<p>
vmalloc分配的内核虚拟内存与kmalloc/get_free_page分配的内核虚拟内存位于不同的区间，不会重叠。因为内核虚拟空间被分区管理，各司其职。进程空间地址分布从0到3G(其实是到PAGE_OFFSET, 在0x86中它等于0xC0000000)，从3G到vmalloc_start这段地址是物理内存映射区域（该区域中包含了内核镜像、物理页面表mem_map等等）。比如我使用的系统内存是64M(可以用free看到)，那么(3G――3G+64M)这片内存就应该映射到物理内存，而vmalloc_start位置应在3G+64M附近（说"附近"因为是在物理内存映射区与vmalloc_start期间还会存在一个8M大小的gap来防止跃界）,vmalloc_end的位置接近4G(说"接近"是因为最后位置系统会保留一片128k大小的区域用于专用页面映射，还有可能会有高端内存映射区，这些都是细节，这里我们不做纠缠)。
</p>

<p>
由get_free_page或Kmalloc函数所分配的连续内存都陷于物理映射区域，所以它们返回的内核虚拟地址和实际物理地址仅仅是相差一个偏移量（PAGE_OFFSET），你可以很方便的将其转化为物理内存地址，同时内核也提供了virt_to_phys（）函数将内核虚拟空间中的物理映射区地址转化为物理地址。要知道，物理内存映射区中的地址与内核页表是有序对应的，系统中的每个物理页面都可以找到它对应的内核虚拟地址（在物理内存映射区中的）。
</p>

<p>
而vmalloc分配的地址则限于vmalloc_start与vmalloc_end之间。每一块vmalloc分配的内核虚拟内存都对应一个<code>vm_struct</code>结构体（可别和<code>vm_area_struct</code>搞混，那可是进程虚拟内存区域的结构），不同的内核虚拟地址被4k大小的空闲区间隔，以防止越界――见下图）。 <strong>与进程虚拟地址的特性一样，这些虚拟地址与物理内存没有简单的位移关系，必须通过内核页表才可转换为物理地址或物理页。它们有可能尚未被映射，在发生缺页时才真正分配物理页面。</strong>
</p>
<blockquote>
内核虚拟地址空间（3G-4G）和进程虚拟地址空间（0-3G）的差别。见上面的粗体部分。
</blockquote>


<h2 id="toc_0.8">高端内存映射</h2>
<ul>
<li>
高端内存概念的由来：如上所述，Linux将4GB的线性地址空间划分成两部分，从0x00000000到0xBFFFFFFF共3GB空间作为用户空间由用户进程独占，这部分线性地址空间并没有固定映射到物理内存空间上；从0xC0000000到0xFFFFFFFF的第4GB线性地址空间作为内核空间，在嵌入式系统中，这部分线性地址空间除了映射物理内存空间之外还要映射处理器内部外设寄存器空间等I/O空间。0xC0000000~high_memory之间的内核逻辑地址空间专用来固定映射系统中的物理内存，也就是说0xC0000000~high_memory之间空间大小与系统的物理内存空间大小是相同的（当然在配置了CONFIG_DISCONTIGMEMD选项的非连续内存系统中，内核逻辑地址空间和物理内存空间一样可能存在内存孔洞），如果系统中的物理内存容量远小于1GB，那么内核线性地址空间中内核逻辑地址空间之上的high_memory~0xFFFFFFFF之间还有足够的空间来固定映射一些I/O空间。可是，如果系统中的物理内存容量（包括内存孔洞）大于1GB，那么就没有足够的内核线性地址空间来固定映射系统全部物理内存以及一些I/O空间了，为了解决这个问题，在x86处理器平台设置了一个经验值：896MB，就是说，如果系统中的物理内存（包括内存孔洞）大于896MB，那么将前896MB物理内存固定映射到内核逻辑地址空间0xC0000000~0xC0000000+896MB（=high_memory）上，而896MB之后的物理内存则不建立到内核线性地址空间的固定映射，这部分内存就叫高端物理内存。此时内核线性地址空间high_memory~0xFFFFFFFF之间的128MB空间就称为高端内存线性地址空间，用来映射高端物理内存和I/O空间。896MB是x86处理器平台的经验值，留了128MB线性地址空间来映射高端内存以及I/O地址空间，在嵌入式系统中可以根据具体情况修改这个阈值，比如，MIPS中将这个值设置为0x20000000B（512MB），那么只有当系统中的物理内存空间容量大于0x20000000B时，内核才需要配置CONFIG_HIGHMEM选项，使能内核对高端内存的分配和映射功能。什么情况需要划分出高端物理内存以及高端物理内存阈值的设置原则见上面的内存页区（zone）概念说明。

<li>
高端线性地址空间：从high_memory到0xFFFFFFFF之间的线性地址空间属于高端线性地址空间，其中VMALLOC_START~VMALLOC_END之间线性地址：（1）被vmalloc()函数用来分配物理上不连续但线性地址空间连续的高端物理内存，或者（2）被vmap()函数用来映射高端或低端物理内存，或者（3）由ioremap()函数来重新映射I/O物理空间。其中PKMAP_BASE开始的LAST_PKMAP（一般等于1024）页线性地址空间：被kmap()函数用来永久映射高端物理内存。FIXADDR_START开始的KM_TYPE_NR*NR_CPUS页线性地址空间：被kmap_atomic()函数用来临时映射高端物理内存，其他未用高端线性地址空间可以用来在系统初始化期间永久映射I/O地址空间。

</ul>

<p>
对 于高端内存，可以通过 alloc_page() 或者其它函数获得对应的 page，但是要想访问实际物理内存，还得把 page 转为线性地址才行（为什么？想想 MMU 是如何访问物理内存的），也就是说，我们需要为高端内存对应的 page 找一个线性空间，这个过程称为高端内存映射。
</p>

<h3 id="toc_0.8.1">高端内存映射有三种方式：</h3>
<ul>
<li>
映射到“内核动态映射空间”

</ul>
<p>
这种方式很简单，因为通过 vmalloc() ，在”内核动态映射空间“申请内存的时候，就可能从高端内存获得页面（参看 vmalloc 的实现），因此说高端内存有可能映射到”内核动态映射空间“ 中。
</p>

<ul>
<li>
永久内核映射

</ul>
<p>
如果是通过 alloc_page() 获得了高端内存对应的 page，如何给它找个线性空间？
</p>

<p>
内核专门为此留出一块线性空间，从 PKMAP_BASE 到 FIXADDR_START ，用于映射高端内存。在 2.4 内核上，这个地址范围是 4G-8M 到 4G-4M 之间。这个空间起叫“内核永久映射空间”或者“永久内核映射空间”这个空间和其它空间使用同样的页目录表，对于内核来说，就是 swapper_pg_dir，对普通进程来说，通过 CR3 寄存器指向。
</p>

<p>
通常情况下，这个空间是 4M 大小，因此仅仅需要一个页表即可，内核通过来 pkmap_page_table 寻找这个页表。通过 kmap()， 可以把一个 page 映射到这个空间来由于这个空间是 4M 大小，最多能同时映射 1024 个 page。因此，对于不使用的的 page，及应该时从这个空间释放掉（也就是解除映射关系），通过 kunmap() ，可以把一个 page 对应的线性地址从这个空间释放出来。 
</p>

<ul>
<li>
临时映射

</ul>
<p>
内核在 FIXADDR_START 到 FIXADDR_TOP 之间保留了一些线性空间用于特殊需求。这个空间称为“固定映射空间”在这个空间中，有一部分用于高端内存的临时映射。 
</p>

<p>
这块空间具有如下特点：
</p>

<ol>
<li>
每个 CPU 占用一块空间

<li>
在每个 CPU 占用的那块空间中，又分为多个小空间，每个小空间大小是 1 个 page，每个小空间用于一个目的，这些目的定义在 kmap_types.h 中的 km_type 中。

</ol>

<p>
当要进行一次临时映射的时候，需要指定映射的目的，根据映射目的，可以找到对应的小空间，然后把这个空间的地址作为映射地址。这意味着一次临时映射会导致以前的映射被覆盖。
</p>

<p>
通过 kmap_atomic() 可实现临时映射。
</p>


<h2 id="toc_0.9">参考资料</h2>
<ul>
<li>
《ARM嵌入式系统开发-软件设计与优化》14.2.3 虚存系统的存储器组织

<li>
《Linux设备驱动程序》 第八章 分配内存；第十五章 内存映射和DMA

</ul>

<h2 id="toc_0.10">相关术语</h2>
<ul>
<li>
<strong>VMA</strong>		Linux中将进程虚拟空间的一个段叫做虚拟内存区域（VMA，Virtual Memory Area）；在Windows中将这个叫做虚拟段（Virtual Section）。操作系统会将进程虚拟空间划分为一个个VMA来管理，基本的划分原则是将相同权限属性的、有相同映像文件的映射成一个VMA，一个进程可以分为以下几种VMA区域：代码VMA、数据VMA、堆VMA、栈VMA。

<li>
<strong>Section &amp; Segment</strong>

<li>
<strong>PAE</strong>		Intel从1995年的Pentium Pro CPU开始采用36位的物理地址，也就是可以访问高达64GB的物理内存。Intel将这个地址扩展方式叫做PAE（Physical Address Extension）。在应用程序中，只有32位的虚拟地址空间，那么应用程序改如何使用这些大于常规的内存空间呢？一个常见的方法是OS提供一个窗口映射的方法，把这些额外的内存映射到进程地址空间中来。在Windows下，叫做AWE（Address Windowing Extensions），在Unix等上采用mmap()系统调用来实现。

</ul>

	</div>
    </div>

    <footer>
	<p id="legal">Copyright &copy; 2012 NIE-YONG. All Rights Reserved.</p>
    </footer>

    <a class="go2top" style="display: none;"><span></span></a>

</body>


<script language="javascript">
dp.SyntaxHighlighter.HighlightAll('code');
</script>

</html>

